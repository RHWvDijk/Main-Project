{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self study 6\n",
    "# Group 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment the original script has been used. The *weights* parameter were set to 'imagenet' and *None*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.applications.xception import Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train+val', 'train')\n",
    "     valid_path = os.path.join(base_dir, 'train+val', 'valid')\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "train_gen, val_gen = get_pcam_generators('C:/Users/Daniel/Documents/')\n",
    "input = Input(input_shape)\n",
    "# get the pretrained model, cut out the top layer\n",
    "pretrained = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "#for layer in pretrained.layers[-4]:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "#for i, layer in enumerate(pretrained.layers):\n",
    "    #layer.trainable = False\n",
    "#    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 16,060,201\n",
      "Non-trainable params: 4,803,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layernames = []\n",
    "for i,layer in enumerate(pretrained.layers):\n",
    "    layernames.append(layer.name)\n",
    "indices = [i for i, s in enumerate(layernames) if 'block14' in s]\n",
    "\n",
    "for layer in pretrained.layers[min(indices):max(indices)+1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    " \n",
    "output = pretrained(input)\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "#for layer in pretrained.layers:\n",
    "#    print(layer, layer.trainable)\n",
    "\n",
    "model = Model(input, output)\n",
    "\n",
    "# note the lower lr compared to the cnn example\n",
    "model.compile(SGD(lr=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "#\n",
    "# print a summary of the model on screen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2 False\n",
      "block1_conv1 True\n",
      "block1_conv1_bn True\n",
      "block1_conv1_act True\n",
      "block1_conv2 True\n",
      "block1_conv2_bn True\n",
      "block1_conv2_act True\n",
      "block2_sepconv1 True\n",
      "block2_sepconv1_bn True\n",
      "block2_sepconv2_act True\n",
      "block2_sepconv2 True\n",
      "block2_sepconv2_bn True\n",
      "conv2d_1 True\n",
      "block2_pool True\n",
      "batch_normalization_1 True\n",
      "add_1 True\n",
      "block3_sepconv1_act True\n",
      "block3_sepconv1 True\n",
      "block3_sepconv1_bn True\n",
      "block3_sepconv2_act True\n",
      "block3_sepconv2 True\n",
      "block3_sepconv2_bn True\n",
      "conv2d_2 True\n",
      "block3_pool True\n",
      "batch_normalization_2 True\n",
      "add_2 True\n",
      "block4_sepconv1_act True\n",
      "block4_sepconv1 True\n",
      "block4_sepconv1_bn True\n",
      "block4_sepconv2_act True\n",
      "block4_sepconv2 True\n",
      "block4_sepconv2_bn True\n",
      "conv2d_3 True\n",
      "block4_pool True\n",
      "batch_normalization_3 True\n",
      "add_3 True\n",
      "block5_sepconv1_act True\n",
      "block5_sepconv1 True\n",
      "block5_sepconv1_bn True\n",
      "block5_sepconv2_act True\n",
      "block5_sepconv2 True\n",
      "block5_sepconv2_bn True\n",
      "block5_sepconv3_act True\n",
      "block5_sepconv3 True\n",
      "block5_sepconv3_bn True\n",
      "add_4 True\n",
      "block6_sepconv1_act True\n",
      "block6_sepconv1 True\n",
      "block6_sepconv1_bn True\n",
      "block6_sepconv2_act True\n",
      "block6_sepconv2 True\n",
      "block6_sepconv2_bn True\n",
      "block6_sepconv3_act True\n",
      "block6_sepconv3 True\n",
      "block6_sepconv3_bn True\n",
      "add_5 True\n",
      "block7_sepconv1_act True\n",
      "block7_sepconv1 True\n",
      "block7_sepconv1_bn True\n",
      "block7_sepconv2_act True\n",
      "block7_sepconv2 True\n",
      "block7_sepconv2_bn True\n",
      "block7_sepconv3_act True\n",
      "block7_sepconv3 True\n",
      "block7_sepconv3_bn True\n",
      "add_6 True\n",
      "block8_sepconv1_act True\n",
      "block8_sepconv1 True\n",
      "block8_sepconv1_bn True\n",
      "block8_sepconv2_act True\n",
      "block8_sepconv2 True\n",
      "block8_sepconv2_bn True\n",
      "block8_sepconv3_act True\n",
      "block8_sepconv3 True\n",
      "block8_sepconv3_bn True\n",
      "add_7 True\n",
      "block9_sepconv1_act True\n",
      "block9_sepconv1 True\n",
      "block9_sepconv1_bn True\n",
      "block9_sepconv2_act True\n",
      "block9_sepconv2 True\n",
      "block9_sepconv2_bn True\n",
      "block9_sepconv3_act True\n",
      "block9_sepconv3 True\n",
      "block9_sepconv3_bn True\n",
      "add_8 True\n",
      "block10_sepconv1_act True\n",
      "block10_sepconv1 True\n",
      "block10_sepconv1_bn True\n",
      "block10_sepconv2_act True\n",
      "block10_sepconv2 True\n",
      "block10_sepconv2_bn True\n",
      "block10_sepconv3_act True\n",
      "block10_sepconv3 True\n",
      "block10_sepconv3_bn True\n",
      "add_9 True\n",
      "block11_sepconv1_act True\n",
      "block11_sepconv1 True\n",
      "block11_sepconv1_bn True\n",
      "block11_sepconv2_act True\n",
      "block11_sepconv2 True\n",
      "block11_sepconv2_bn True\n",
      "block11_sepconv3_act True\n",
      "block11_sepconv3 True\n",
      "block11_sepconv3_bn True\n",
      "add_10 True\n",
      "block12_sepconv1_act True\n",
      "block12_sepconv1 True\n",
      "block12_sepconv1_bn True\n",
      "block12_sepconv2_act True\n",
      "block12_sepconv2 True\n",
      "block12_sepconv2_bn True\n",
      "block12_sepconv3_act True\n",
      "block12_sepconv3 True\n",
      "block12_sepconv3_bn True\n",
      "add_11 True\n",
      "block13_sepconv1_act True\n",
      "block13_sepconv1 True\n",
      "block13_sepconv1_bn True\n",
      "block13_sepconv2_act True\n",
      "block13_sepconv2 True\n",
      "block13_sepconv2_bn True\n",
      "conv2d_4 True\n",
      "block13_pool True\n",
      "batch_normalization_4 True\n",
      "add_12 True\n",
      "block14_sepconv1 False\n",
      "block14_sepconv1_bn False\n",
      "block14_sepconv1_act False\n",
      "block14_sepconv2 False\n",
      "block14_sepconv2_bn False\n",
      "block14_sepconv2_act False\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(pretrained.layers):\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,layer in enumerate(model.layers):\n",
    "    #print(i,layer.name)\n",
    "\n",
    "#for layer in model.layers:\n",
    "#    print(layer.output_shape)\n",
    "# get the data generators\n",
    "\n",
    "\n",
    "# save the model and weights\n",
    "model_name = 'Xception weights ImageNet 14 off'\n",
    "model_filepath = model_name + '.json'\n",
    "weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(model_filepath, 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "# define the model checkpoint and Tensorboard callbacks\n",
    "checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "# train the model, note that we define \"mini-epochs\"\n",
    "train_steps = train_gen.n//train_gen.batch_size//20\n",
    "val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "# since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "# not used during training\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=10,\n",
    "                    callbacks=callbacks_list)\n",
    "\n",
    "# print a summary of the model on screen\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers except the last 4 layers\n",
    "for i,layer in enumerate(pretrained.layers):\n",
    "    #layer.trainable = False\n",
    "    print(i, layer.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
