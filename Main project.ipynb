{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Model 'Xception' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.applications.xception import Xception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train+val','train')\n",
    "     valid_path = os.path.join(base_dir, 'train+val','valid')\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "train_gen, val_gen = get_pcam_generators('C:/Users/Daniel/Documents/')\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "input = Input(input_shape)\n",
    "# get the pretrained model, cut out the top layer\n",
    "pretrained = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "layernames = []\n",
    "for i,layer in enumerate(pretrained.layers):\n",
    "    layernames.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block14\n",
      "0 input_4 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_5 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_5 False\n",
      "15 add_13 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_6 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_6 False\n",
      "25 add_14 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_7 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_7 False\n",
      "35 add_15 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_16 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_17 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_18 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_19 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_20 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_21 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_22 False\n",
      "106 block12_sepconv1_act False\n",
      "107 block12_sepconv1 False\n",
      "108 block12_sepconv1_bn False\n",
      "109 block12_sepconv2_act False\n",
      "110 block12_sepconv2 False\n",
      "111 block12_sepconv2_bn False\n",
      "112 block12_sepconv3_act False\n",
      "113 block12_sepconv3 False\n",
      "114 block12_sepconv3_bn False\n",
      "115 add_23 False\n",
      "116 block13_sepconv1_act False\n",
      "117 block13_sepconv1 False\n",
      "118 block13_sepconv1_bn False\n",
      "119 block13_sepconv2_act False\n",
      "120 block13_sepconv2 False\n",
      "121 block13_sepconv2_bn False\n",
      "122 conv2d_8 False\n",
      "123 block13_pool False\n",
      "124 batch_normalization_8 False\n",
      "125 add_24 False\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 4,750,849\n",
      "Non-trainable params: 16,112,680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 38s 170ms/step - loss: 0.6206 - acc: 0.6669 - val_loss: 0.6827 - val_acc: 0.6175\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68269, saving model to Xception2 block14_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 35s 155ms/step - loss: 0.5121 - acc: 0.7719 - val_loss: 0.6253 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68269 to 0.62532, saving model to Xception2 block14_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 35s 154ms/step - loss: 0.4816 - acc: 0.7778 - val_loss: 0.5939 - val_acc: 0.7013\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62532 to 0.59386, saving model to Xception2 block14_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 35s 154ms/step - loss: 0.4551 - acc: 0.7914 - val_loss: 0.5685 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59386 to 0.56850, saving model to Xception2 block14_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.4371 - acc: 0.8028 - val_loss: 0.5891 - val_acc: 0.7163\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56850\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.4340 - acc: 0.7975 - val_loss: 0.5731 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56850\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 35s 156ms/step - loss: 0.4202 - acc: 0.8072 - val_loss: 0.6054 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56850\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 37s 166ms/step - loss: 0.4213 - acc: 0.8113 - val_loss: 0.5402 - val_acc: 0.7325\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56850 to 0.54018, saving model to Xception2 block14_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 0.4101 - acc: 0.8174 - val_loss: 0.5946 - val_acc: 0.7025\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54018\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 0.4042 - acc: 0.8140 - val_loss: 0.5910 - val_acc: 0.7113\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54018\n",
      "block13\n",
      "0 input_6 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_9 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_9 False\n",
      "15 add_25 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_10 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_10 False\n",
      "25 add_26 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_11 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_11 False\n",
      "35 add_27 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_28 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_29 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_30 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_31 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_32 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_33 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_34 False\n",
      "106 block12_sepconv1_act False\n",
      "107 block12_sepconv1 False\n",
      "108 block12_sepconv1_bn False\n",
      "109 block12_sepconv2_act False\n",
      "110 block12_sepconv2 False\n",
      "111 block12_sepconv2_bn False\n",
      "112 block12_sepconv3_act False\n",
      "113 block12_sepconv3 False\n",
      "114 block12_sepconv3_bn False\n",
      "115 add_35 False\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_12 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_12 True\n",
      "125 add_36 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 6,790,433\n",
      "Non-trainable params: 14,073,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 0.5880 - acc: 0.6928 - val_loss: 1.2215 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.22154, saving model to Xception2 block13_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.4535 - acc: 0.7953 - val_loss: 1.2136 - val_acc: 0.6125\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.22154 to 1.21365, saving model to Xception2 block13_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 36s 158ms/step - loss: 0.4239 - acc: 0.8053 - val_loss: 1.3782 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.21365\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.4027 - acc: 0.8215 - val_loss: 1.0459 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.21365 to 1.04591, saving model to Xception2 block13_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3836 - acc: 0.8289 - val_loss: 1.1396 - val_acc: 0.6012\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.04591\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3838 - acc: 0.8300 - val_loss: 1.0625 - val_acc: 0.6288\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.04591\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3721 - acc: 0.8332 - val_loss: 0.9640 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.04591 to 0.96399, saving model to Xception2 block13_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3783 - acc: 0.8313 - val_loss: 0.8385 - val_acc: 0.6288\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.96399 to 0.83855, saving model to Xception2 block13_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3538 - acc: 0.8474 - val_loss: 0.8573 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.83855\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3409 - acc: 0.8524 - val_loss: 0.8731 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.83855\n",
      "block12\n",
      "0 input_8 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_13 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_13 False\n",
      "15 add_37 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_14 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_14 False\n",
      "25 add_38 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_15 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_15 False\n",
      "35 add_39 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_40 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_41 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_42 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_43 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_44 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_45 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_46 False\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_47 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_16 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_16 True\n",
      "125 add_48 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 8,404,409\n",
      "Non-trainable params: 12,459,120\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 43s 191ms/step - loss: 0.5991 - acc: 0.6821 - val_loss: 0.6690 - val_acc: 0.5787\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66905, saving model to Xception2 block12_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.4531 - acc: 0.7911 - val_loss: 0.6315 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66905 to 0.63147, saving model to Xception2 block12_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.4164 - acc: 0.8107 - val_loss: 0.6570 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63147\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3718 - acc: 0.8310 - val_loss: 0.5562 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63147 to 0.55617, saving model to Xception2 block12_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3736 - acc: 0.8333 - val_loss: 0.6079 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55617\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3849 - acc: 0.8299 - val_loss: 0.5770 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55617\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3680 - acc: 0.8364 - val_loss: 0.5580 - val_acc: 0.7512\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55617\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 41s 181ms/step - loss: 0.3523 - acc: 0.8443 - val_loss: 0.5316 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55617 to 0.53155, saving model to Xception2 block12_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3420 - acc: 0.8488 - val_loss: 0.5412 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53155\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3506 - acc: 0.8525 - val_loss: 0.5751 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53155\n",
      "block11\n",
      "0 input_10 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_17 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_17 False\n",
      "15 add_49 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_18 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_18 False\n",
      "25 add_50 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_19 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_19 False\n",
      "35 add_51 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_52 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_53 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_54 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_55 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_56 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_57 False\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_58 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_59 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_20 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_20 True\n",
      "125 add_60 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 10,018,385\n",
      "Non-trainable params: 10,845,144\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.5767 - acc: 0.7046 - val_loss: 0.6539 - val_acc: 0.6188\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65390, saving model to Xception2 block11_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.4396 - acc: 0.7990 - val_loss: 0.6828 - val_acc: 0.6288\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.65390\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.4025 - acc: 0.8193 - val_loss: 0.8024 - val_acc: 0.6050\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.65390\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3939 - acc: 0.8224 - val_loss: 0.6558 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.65390\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3819 - acc: 0.8293 - val_loss: 0.5312 - val_acc: 0.7375\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65390 to 0.53125, saving model to Xception2 block11_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3527 - acc: 0.8501 - val_loss: 0.5415 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53125\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3555 - acc: 0.8433 - val_loss: 0.5322 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.53125\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3673 - acc: 0.8367 - val_loss: 0.5381 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53125\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3587 - acc: 0.8426 - val_loss: 0.5219 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53125 to 0.52185, saving model to Xception2 block11_weights.hdf5\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3432 - acc: 0.8474 - val_loss: 0.5273 - val_acc: 0.7350\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.52185\n",
      "block10\n",
      "0 input_12 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_21 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_21 False\n",
      "15 add_61 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_22 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_22 False\n",
      "25 add_62 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_23 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_23 False\n",
      "35 add_63 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_64 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_65 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_66 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_67 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_68 False\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_69 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_70 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_71 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_24 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_24 True\n",
      "125 add_72 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 11,632,361\n",
      "Non-trainable params: 9,231,168\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.5743 - acc: 0.7032 - val_loss: 0.6326 - val_acc: 0.6212\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63256, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 51s 226ms/step - loss: 0.4279 - acc: 0.8086 - val_loss: 0.6309 - val_acc: 0.6600\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.63256 to 0.63090, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3878 - acc: 0.8244 - val_loss: 0.5945 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63090 to 0.59447, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3818 - acc: 0.8318 - val_loss: 0.5259 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.59447 to 0.52595, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3731 - acc: 0.8310 - val_loss: 0.5188 - val_acc: 0.7512\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.52595 to 0.51877, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 51s 226ms/step - loss: 0.3633 - acc: 0.8400 - val_loss: 0.5252 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51877\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3608 - acc: 0.8413 - val_loss: 0.5046 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51877 to 0.50456, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3430 - acc: 0.8514 - val_loss: 0.5070 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.50456\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3440 - acc: 0.8485 - val_loss: 0.4914 - val_acc: 0.7625\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50456 to 0.49144, saving model to Xception2 block10_weights.hdf5\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 51s 227ms/step - loss: 0.3339 - acc: 0.8510 - val_loss: 0.4947 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.49144\n",
      "block9\n",
      "0 input_14 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_25 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_25 False\n",
      "15 add_73 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_26 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_26 False\n",
      "25 add_74 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_27 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_27 False\n",
      "35 add_75 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_76 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_77 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_78 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_79 False\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_80 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_81 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_82 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_83 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_28 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_28 True\n",
      "125 add_84 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 13,246,337\n",
      "Non-trainable params: 7,617,192\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 59s 260ms/step - loss: 0.5867 - acc: 0.6942 - val_loss: 0.6933 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69332, saving model to Xception2 block9_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.4505 - acc: 0.7989 - val_loss: 0.5723 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69332 to 0.57230, saving model to Xception2 block9_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.4102 - acc: 0.8135 - val_loss: 0.5660 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57230 to 0.56604, saving model to Xception2 block9_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.3868 - acc: 0.8286 - val_loss: 0.5291 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.56604 to 0.52911, saving model to Xception2 block9_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 56s 248ms/step - loss: 0.3695 - acc: 0.8337 - val_loss: 0.5675 - val_acc: 0.7087\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52911\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.3577 - acc: 0.8428 - val_loss: 0.5467 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.52911\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 56s 247ms/step - loss: 0.3375 - acc: 0.8528 - val_loss: 0.5140 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52911 to 0.51398, saving model to Xception2 block9_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.3522 - acc: 0.8458 - val_loss: 0.5017 - val_acc: 0.7575\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51398 to 0.50172, saving model to Xception2 block9_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.3437 - acc: 0.8492 - val_loss: 0.5102 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.50172\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 56s 249ms/step - loss: 0.3246 - acc: 0.8586 - val_loss: 0.5046 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.50172\n",
      "block8\n",
      "0 input_16 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_29 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_29 False\n",
      "15 add_85 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_30 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_30 False\n",
      "25 add_86 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_31 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_31 False\n",
      "35 add_87 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_88 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_89 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_90 False\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_91 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_92 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_93 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_94 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_95 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_32 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_32 True\n",
      "125 add_96 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 14,860,313\n",
      "Non-trainable params: 6,003,216\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 64s 284ms/step - loss: 0.5695 - acc: 0.7111 - val_loss: 0.7175 - val_acc: 0.6012\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71747, saving model to Xception2 block8_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.4263 - acc: 0.8061 - val_loss: 0.5696 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71747 to 0.56959, saving model to Xception2 block8_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.4006 - acc: 0.8147 - val_loss: 0.5473 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56959 to 0.54730, saving model to Xception2 block8_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3981 - acc: 0.8232 - val_loss: 0.5541 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54730\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3669 - acc: 0.8367 - val_loss: 0.4589 - val_acc: 0.7775\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.54730 to 0.45887, saving model to Xception2 block8_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3525 - acc: 0.8451 - val_loss: 0.5007 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.45887\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3543 - acc: 0.8464 - val_loss: 0.4474 - val_acc: 0.8013\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45887 to 0.44739, saving model to Xception2 block8_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3279 - acc: 0.8583 - val_loss: 0.5150 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.44739\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 60s 269ms/step - loss: 0.3248 - acc: 0.8603 - val_loss: 0.5393 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.44739\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 61s 269ms/step - loss: 0.3170 - acc: 0.8646 - val_loss: 0.5000 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.44739\n",
      "block7\n",
      "0 input_18 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_33 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_33 False\n",
      "15 add_97 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_34 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_34 False\n",
      "25 add_98 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_35 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_35 False\n",
      "35 add_99 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_100 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_101 False\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_102 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_103 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_104 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_105 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_106 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_107 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_36 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_36 True\n",
      "125 add_108 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 16,474,289\n",
      "Non-trainable params: 4,389,240\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 69s 308ms/step - loss: 0.5858 - acc: 0.6886 - val_loss: 0.6187 - val_acc: 0.6412\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61865, saving model to Xception2 block7_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 65s 291ms/step - loss: 0.4480 - acc: 0.7937 - val_loss: 0.6359 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.61865\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 66s 292ms/step - loss: 0.4021 - acc: 0.8224 - val_loss: 0.7699 - val_acc: 0.6150\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.61865\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 66s 292ms/step - loss: 0.3886 - acc: 0.8268 - val_loss: 0.5560 - val_acc: 0.7025\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61865 to 0.55597, saving model to Xception2 block7_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 66s 291ms/step - loss: 0.3592 - acc: 0.8401 - val_loss: 0.6210 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.55597\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 65s 291ms/step - loss: 0.3509 - acc: 0.8464 - val_loss: 0.5574 - val_acc: 0.7113\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.55597\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 65s 291ms/step - loss: 0.3487 - acc: 0.8467 - val_loss: 0.6178 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.55597\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 65s 291ms/step - loss: 0.3369 - acc: 0.8549 - val_loss: 0.5334 - val_acc: 0.7125\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55597 to 0.53343, saving model to Xception2 block7_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 65s 291ms/step - loss: 0.3131 - acc: 0.8671 - val_loss: 0.6871 - val_acc: 0.6625\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53343\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 66s 291ms/step - loss: 0.3137 - acc: 0.8636 - val_loss: 0.5572 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53343\n",
      "block6\n",
      "0 input_20 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_37 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_37 False\n",
      "15 add_109 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_38 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_38 False\n",
      "25 add_110 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_39 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_39 False\n",
      "35 add_111 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_112 False\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_113 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_114 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_115 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_116 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_117 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_118 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_119 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_40 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_40 True\n",
      "125 add_120 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 18,088,265\n",
      "Non-trainable params: 2,775,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 75s 332ms/step - loss: 0.5757 - acc: 0.6944 - val_loss: 0.7463 - val_acc: 0.5713\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74633, saving model to Xception2 block6_weights.hdf5\n",
      "Epoch 2/10\n",
      " 94/225 [===========>..................] - ETA: 39s - loss: 0.4474 - acc: 0.7979"
     ]
    }
   ],
   "source": [
    "for j in range(14,0,-1): #verander hier het aantal blokken dat je pretrained model heeft\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    input = Input(input_shape)\n",
    "    pretrained = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    for layer in pretrained.layers:\n",
    "            layer.trainable = False            \n",
    "\n",
    "    string = 'block'+str(j)\n",
    "    indices = [i for i, s in enumerate(layernames) if string in s]      \n",
    "    for layer in pretrained.layers[min(indices):]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = pretrained(input)\n",
    "    output = GlobalAveragePooling2D()(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    #for layer in pretrained.layers:\n",
    "    #    print(layer, layer.trainable)\n",
    "\n",
    "    model = Model(input, output)\n",
    "    model.compile(SGD(lr=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    #\n",
    "    # print a summary of the model on screen\n",
    "    print(string)\n",
    "    for i,layer in enumerate(pretrained.layers):\n",
    "        print(i,layer.name,layer.trainable)\n",
    "    model.summary()\n",
    "        \n",
    "    # save the model and weights\n",
    "    model_name = 'Xception2 '+string\n",
    "    model_filepath = model_name + '.json'\n",
    "    weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "    model_json = model.to_json() # serialize model to JSON\n",
    "    with open(model_filepath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "\n",
    "    # define the model checkpoint and Tensorboard callbacks\n",
    "    checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "    callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "    # train the model, note that we define \"mini-epochs\"\n",
    "    train_steps = train_gen.n//train_gen.batch_size//20\n",
    "    val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "    # since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "    # not used during training\n",
    "\n",
    "    history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=10,\n",
    "                        callbacks=callbacks_list)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
