{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Model 'Xception' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 144000 images belonging to 2 classes.\n",
      "Found 16000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def get_pcam_generators(base_dir, train_batch_size=32, val_batch_size=32):\n",
    "\n",
    "     # dataset parameters\n",
    "     train_path = os.path.join(base_dir, 'train+val','train')\n",
    "     valid_path = os.path.join(base_dir, 'train+val','valid')\n",
    "\n",
    "     # instantiate data generators\n",
    "     datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "     train_gen = datagen.flow_from_directory(train_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=train_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                             target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                                             batch_size=val_batch_size,\n",
    "                                             class_mode='binary')\n",
    "\n",
    "     return train_gen, val_gen\n",
    "\n",
    "# the size of the images in the PCAM dataset\n",
    "IMAGE_SIZE = 96\n",
    "\n",
    "train_gen, val_gen = get_pcam_generators('C:/Users/Daniel/Documents/')\n",
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "input = Input(input_shape)\n",
    "# get the pretrained model, cut out the top layer\n",
    "pretrained = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "layernames = []\n",
    "for i,layer in enumerate(pretrained.layers):\n",
    "    layernames.append(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block14\n",
      "0 input_4 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_5 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_5 False\n",
      "15 add_13 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_6 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_6 False\n",
      "25 add_14 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_7 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_7 False\n",
      "35 add_15 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_16 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_17 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_18 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_19 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_20 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_21 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_22 False\n",
      "106 block12_sepconv1_act False\n",
      "107 block12_sepconv1 False\n",
      "108 block12_sepconv1_bn False\n",
      "109 block12_sepconv2_act False\n",
      "110 block12_sepconv2 False\n",
      "111 block12_sepconv2_bn False\n",
      "112 block12_sepconv3_act False\n",
      "113 block12_sepconv3 False\n",
      "114 block12_sepconv3_bn False\n",
      "115 add_23 False\n",
      "116 block13_sepconv1_act False\n",
      "117 block13_sepconv1 False\n",
      "118 block13_sepconv1_bn False\n",
      "119 block13_sepconv2_act False\n",
      "120 block13_sepconv2 False\n",
      "121 block13_sepconv2_bn False\n",
      "122 conv2d_8 False\n",
      "123 block13_pool False\n",
      "124 batch_normalization_8 False\n",
      "125 add_24 False\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 4,750,849\n",
      "Non-trainable params: 16,112,680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 34s 152ms/step - loss: 0.6185 - acc: 0.6708 - val_loss: 0.6198 - val_acc: 0.6600\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.61979, saving model to Xception3 block14_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.5104 - acc: 0.7685 - val_loss: 0.6679 - val_acc: 0.6663\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.61979\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4630 - acc: 0.7857 - val_loss: 0.6768 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.61979\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4560 - acc: 0.7937 - val_loss: 0.5609 - val_acc: 0.7238\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.61979 to 0.56090, saving model to Xception3 block14_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4437 - acc: 0.7981 - val_loss: 0.6118 - val_acc: 0.7063\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56090\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4340 - acc: 0.8021 - val_loss: 0.6316 - val_acc: 0.6813\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56090\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4227 - acc: 0.8108 - val_loss: 0.6238 - val_acc: 0.6687\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56090\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4073 - acc: 0.8183 - val_loss: 0.6746 - val_acc: 0.6425\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56090\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 31s 138ms/step - loss: 0.4086 - acc: 0.8176 - val_loss: 0.6613 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56090\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 31s 139ms/step - loss: 0.3961 - acc: 0.8237 - val_loss: 0.7578 - val_acc: 0.6188\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56090\n",
      "block13\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_8 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_9 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_10 False\n",
      "106 block12_sepconv1_act False\n",
      "107 block12_sepconv1 False\n",
      "108 block12_sepconv1_bn False\n",
      "109 block12_sepconv2_act False\n",
      "110 block12_sepconv2 False\n",
      "111 block12_sepconv2_bn False\n",
      "112 block12_sepconv3_act False\n",
      "113 block12_sepconv3 False\n",
      "114 block12_sepconv3_bn False\n",
      "115 add_11 False\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 6,790,433\n",
      "Non-trainable params: 14,073,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 37s 167ms/step - loss: 0.6007 - acc: 0.6839 - val_loss: 0.8948 - val_acc: 0.6175\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.89484, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.4654 - acc: 0.7840 - val_loss: 0.9853 - val_acc: 0.6225\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.89484\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.4155 - acc: 0.8121 - val_loss: 0.8707 - val_acc: 0.6575\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89484 to 0.87067, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.4023 - acc: 0.8208 - val_loss: 0.8409 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.87067 to 0.84092, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.3877 - acc: 0.8251 - val_loss: 0.6809 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.84092 to 0.68094, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 36s 158ms/step - loss: 0.3782 - acc: 0.8293 - val_loss: 0.7892 - val_acc: 0.6713\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68094\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.3759 - acc: 0.8319 - val_loss: 0.6280 - val_acc: 0.7350\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68094 to 0.62804, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.3674 - acc: 0.8382 - val_loss: 0.5495 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62804 to 0.54954, saving model to Xception3 block13_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 35s 158ms/step - loss: 0.3640 - acc: 0.8387 - val_loss: 0.5630 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54954\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 36s 158ms/step - loss: 0.3604 - acc: 0.8403 - val_loss: 0.5887 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54954\n",
      "block12\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_8 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_9 False\n",
      "96 block11_sepconv1_act False\n",
      "97 block11_sepconv1 False\n",
      "98 block11_sepconv1_bn False\n",
      "99 block11_sepconv2_act False\n",
      "100 block11_sepconv2 False\n",
      "101 block11_sepconv2_bn False\n",
      "102 block11_sepconv3_act False\n",
      "103 block11_sepconv3 False\n",
      "104 block11_sepconv3_bn False\n",
      "105 add_10 False\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 8,404,409\n",
      "Non-trainable params: 12,459,120\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 43s 189ms/step - loss: 0.5962 - acc: 0.6837 - val_loss: 0.7023 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70234, saving model to Xception3 block12_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.4402 - acc: 0.8000 - val_loss: 0.7528 - val_acc: 0.6550\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.70234\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.4176 - acc: 0.8158 - val_loss: 0.6429 - val_acc: 0.6763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70234 to 0.64287, saving model to Xception3 block12_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3837 - acc: 0.8279 - val_loss: 0.6574 - val_acc: 0.6987\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.64287\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3807 - acc: 0.8347 - val_loss: 0.7964 - val_acc: 0.6375\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.64287\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3685 - acc: 0.8360 - val_loss: 0.6308 - val_acc: 0.6475\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64287 to 0.63080, saving model to Xception3 block12_weights.hdf5\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3605 - acc: 0.8424 - val_loss: 0.5696 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.63080 to 0.56961, saving model to Xception3 block12_weights.hdf5\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3483 - acc: 0.8451 - val_loss: 0.6061 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56961\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3531 - acc: 0.8454 - val_loss: 0.5963 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56961\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.3500 - acc: 0.8435 - val_loss: 0.5415 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.56961 to 0.54154, saving model to Xception3 block12_weights.hdf5\n",
      "block11\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_8 False\n",
      "86 block10_sepconv1_act False\n",
      "87 block10_sepconv1 False\n",
      "88 block10_sepconv1_bn False\n",
      "89 block10_sepconv2_act False\n",
      "90 block10_sepconv2 False\n",
      "91 block10_sepconv2_bn False\n",
      "92 block10_sepconv3_act False\n",
      "93 block10_sepconv3 False\n",
      "94 block10_sepconv3_bn False\n",
      "95 add_9 False\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 10,018,385\n",
      "Non-trainable params: 10,845,144\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 48s 211ms/step - loss: 0.5833 - acc: 0.7011 - val_loss: 0.6323 - val_acc: 0.6138\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63232, saving model to Xception3 block11_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.4386 - acc: 0.7997 - val_loss: 0.7299 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.63232\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.4116 - acc: 0.8125 - val_loss: 0.5790 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.63232 to 0.57897, saving model to Xception3 block11_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3895 - acc: 0.8224 - val_loss: 0.5829 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.57897\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3865 - acc: 0.8253 - val_loss: 0.5177 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.57897 to 0.51773, saving model to Xception3 block11_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3788 - acc: 0.8282 - val_loss: 0.5229 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51773\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3666 - acc: 0.8382 - val_loss: 0.5613 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.51773\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3461 - acc: 0.8486 - val_loss: 0.5193 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51773\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3445 - acc: 0.8474 - val_loss: 0.5497 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51773\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 46s 203ms/step - loss: 0.3502 - acc: 0.8490 - val_loss: 0.4908 - val_acc: 0.7438\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.51773 to 0.49082, saving model to Xception3 block11_weights.hdf5\n",
      "block10\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act False\n",
      "77 block9_sepconv1 False\n",
      "78 block9_sepconv1_bn False\n",
      "79 block9_sepconv2_act False\n",
      "80 block9_sepconv2 False\n",
      "81 block9_sepconv2_bn False\n",
      "82 block9_sepconv3_act False\n",
      "83 block9_sepconv3 False\n",
      "84 block9_sepconv3_bn False\n",
      "85 add_8 False\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 11,632,361\n",
      "Non-trainable params: 9,231,168\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 53s 233ms/step - loss: 0.5780 - acc: 0.6947 - val_loss: 0.6689 - val_acc: 0.5775\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66890, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.4418 - acc: 0.7989 - val_loss: 0.6009 - val_acc: 0.6637\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66890 to 0.60085, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.4000 - acc: 0.8193 - val_loss: 0.5671 - val_acc: 0.7238\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.60085 to 0.56710, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.4042 - acc: 0.8189 - val_loss: 0.5703 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56710\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3708 - acc: 0.8361 - val_loss: 0.5515 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.56710 to 0.55153, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3833 - acc: 0.8289 - val_loss: 0.5423 - val_acc: 0.7312\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.55153 to 0.54227, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3638 - acc: 0.8387 - val_loss: 0.5161 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54227 to 0.51611, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3615 - acc: 0.8496 - val_loss: 0.4825 - val_acc: 0.7950\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51611 to 0.48251, saving model to Xception3 block10_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3277 - acc: 0.8575 - val_loss: 0.5091 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48251\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 50s 224ms/step - loss: 0.3353 - acc: 0.8567 - val_loss: 0.5498 - val_acc: 0.6987\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48251\n",
      "block9\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act False\n",
      "67 block8_sepconv1 False\n",
      "68 block8_sepconv1_bn False\n",
      "69 block8_sepconv2_act False\n",
      "70 block8_sepconv2 False\n",
      "71 block8_sepconv2_bn False\n",
      "72 block8_sepconv3_act False\n",
      "73 block8_sepconv3 False\n",
      "74 block8_sepconv3_bn False\n",
      "75 add_7 False\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 13,246,337\n",
      "Non-trainable params: 7,617,192\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 58s 256ms/step - loss: 0.5885 - acc: 0.6869 - val_loss: 0.6472 - val_acc: 0.5975\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64717, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.4559 - acc: 0.7949 - val_loss: 0.5890 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64717 to 0.58898, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.4119 - acc: 0.8144 - val_loss: 0.5274 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58898 to 0.52735, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3886 - acc: 0.8231 - val_loss: 0.5821 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.52735\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3766 - acc: 0.8351 - val_loss: 0.5698 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.52735\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3778 - acc: 0.8346 - val_loss: 0.5259 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.52735 to 0.52587, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3475 - acc: 0.8485 - val_loss: 0.5193 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.52587 to 0.51927, saving model to Xception3 block9_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3369 - acc: 0.8521 - val_loss: 0.5054 - val_acc: 0.7650\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51927 to 0.50543, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3329 - acc: 0.8553 - val_loss: 0.4850 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.50543 to 0.48500, saving model to Xception3 block9_weights.hdf5\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 55s 245ms/step - loss: 0.3354 - acc: 0.8503 - val_loss: 0.5254 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48500\n",
      "block8\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act False\n",
      "57 block7_sepconv1 False\n",
      "58 block7_sepconv1_bn False\n",
      "59 block7_sepconv2_act False\n",
      "60 block7_sepconv2 False\n",
      "61 block7_sepconv2_bn False\n",
      "62 block7_sepconv3_act False\n",
      "63 block7_sepconv3 False\n",
      "64 block7_sepconv3_bn False\n",
      "65 add_6 False\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 14,860,313\n",
      "Non-trainable params: 6,003,216\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 63s 278ms/step - loss: 0.5753 - acc: 0.6971 - val_loss: 0.6592 - val_acc: 0.6112\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65923, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.4413 - acc: 0.7969 - val_loss: 0.5757 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65923 to 0.57568, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 60s 266ms/step - loss: 0.4019 - acc: 0.8201 - val_loss: 0.5558 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.57568 to 0.55578, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3808 - acc: 0.8347 - val_loss: 0.5730 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.55578\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3719 - acc: 0.8393 - val_loss: 0.4966 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.55578 to 0.49663, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3388 - acc: 0.8594 - val_loss: 0.4941 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49663 to 0.49415, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3476 - acc: 0.8450 - val_loss: 0.4741 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49415 to 0.47413, saving model to Xception3 block8_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 60s 266ms/step - loss: 0.3392 - acc: 0.8596 - val_loss: 0.5813 - val_acc: 0.6987\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.47413\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3295 - acc: 0.8603 - val_loss: 0.5771 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.47413\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 60s 267ms/step - loss: 0.3266 - acc: 0.8608 - val_loss: 0.4534 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.47413 to 0.45341, saving model to Xception3 block8_weights.hdf5\n",
      "block7\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act False\n",
      "47 block6_sepconv1 False\n",
      "48 block6_sepconv1_bn False\n",
      "49 block6_sepconv2_act False\n",
      "50 block6_sepconv2 False\n",
      "51 block6_sepconv2_bn False\n",
      "52 block6_sepconv3_act False\n",
      "53 block6_sepconv3 False\n",
      "54 block6_sepconv3_bn False\n",
      "55 add_5 False\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 16,474,289\n",
      "Non-trainable params: 4,389,240\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 68s 300ms/step - loss: 0.5585 - acc: 0.7149 - val_loss: 0.6291 - val_acc: 0.6225\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62913, saving model to Xception3 block7_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.4389 - acc: 0.8001 - val_loss: 0.5530 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62913 to 0.55300, saving model to Xception3 block7_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.4020 - acc: 0.8207 - val_loss: 0.7366 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.55300\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3849 - acc: 0.8271 - val_loss: 0.5153 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.55300 to 0.51529, saving model to Xception3 block7_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3600 - acc: 0.8378 - val_loss: 0.6469 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.51529\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3524 - acc: 0.8399 - val_loss: 0.5707 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.51529\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3421 - acc: 0.8512 - val_loss: 0.6463 - val_acc: 0.6462\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.51529\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3205 - acc: 0.8631 - val_loss: 0.5864 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.51529\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3284 - acc: 0.8585 - val_loss: 0.6361 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.51529\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 65s 288ms/step - loss: 0.3179 - acc: 0.8654 - val_loss: 0.5555 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.51529\n",
      "block6\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act False\n",
      "37 block5_sepconv1 False\n",
      "38 block5_sepconv1_bn False\n",
      "39 block5_sepconv2_act False\n",
      "40 block5_sepconv2 False\n",
      "41 block5_sepconv2_bn False\n",
      "42 block5_sepconv3_act False\n",
      "43 block5_sepconv3 False\n",
      "44 block5_sepconv3_bn False\n",
      "45 add_4 False\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 18,088,265\n",
      "Non-trainable params: 2,775,264\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 73s 323ms/step - loss: 0.5820 - acc: 0.6994 - val_loss: 0.7835 - val_acc: 0.6000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78355, saving model to Xception3 block6_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.4317 - acc: 0.8042 - val_loss: 0.4867 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78355 to 0.48667, saving model to Xception3 block6_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3816 - acc: 0.8313 - val_loss: 0.4900 - val_acc: 0.7538\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.48667\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3579 - acc: 0.8429 - val_loss: 0.6607 - val_acc: 0.6475\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48667\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3494 - acc: 0.8465 - val_loss: 0.5105 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48667\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3275 - acc: 0.8557 - val_loss: 0.6241 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48667\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3175 - acc: 0.8656 - val_loss: 0.9651 - val_acc: 0.6225\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.48667\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 70s 309ms/step - loss: 0.3024 - acc: 0.8728 - val_loss: 0.6000 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48667\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 70s 310ms/step - loss: 0.3015 - acc: 0.8735 - val_loss: 0.8857 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48667\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 70s 309ms/step - loss: 0.2877 - acc: 0.8800 - val_loss: 0.7502 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48667\n",
      "block5\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act False\n",
      "27 block4_sepconv1 False\n",
      "28 block4_sepconv1_bn False\n",
      "29 block4_sepconv2_act False\n",
      "30 block4_sepconv2 False\n",
      "31 block4_sepconv2_bn False\n",
      "32 conv2d_3 False\n",
      "33 block4_pool False\n",
      "34 batch_normalization_3 False\n",
      "35 add_3 False\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_4 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 19,702,241\n",
      "Non-trainable params: 1,161,288\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 78s 345ms/step - loss: 0.5824 - acc: 0.6860 - val_loss: 0.6483 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64827, saving model to Xception3 block5_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.4172 - acc: 0.8115 - val_loss: 0.6538 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.64827\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.3752 - acc: 0.8379 - val_loss: 0.7020 - val_acc: 0.6763\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.64827\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.3494 - acc: 0.8492 - val_loss: 0.6671 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.64827\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.3274 - acc: 0.8560 - val_loss: 0.5738 - val_acc: 0.7188\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.64827 to 0.57383, saving model to Xception3 block5_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.3196 - acc: 0.8653 - val_loss: 0.8206 - val_acc: 0.6512\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.57383\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.3155 - acc: 0.8624 - val_loss: 0.6824 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.57383\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.2979 - acc: 0.8725 - val_loss: 0.6272 - val_acc: 0.7225\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.57383\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.2824 - acc: 0.8811 - val_loss: 0.7984 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.57383\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 74s 330ms/step - loss: 0.2774 - acc: 0.8847 - val_loss: 0.8708 - val_acc: 0.6775\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.57383\n",
      "block4\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act False\n",
      "17 block3_sepconv1 False\n",
      "18 block3_sepconv1_bn False\n",
      "19 block3_sepconv2_act False\n",
      "20 block3_sepconv2 False\n",
      "21 block3_sepconv2_bn False\n",
      "22 conv2d_2 False\n",
      "23 block3_pool False\n",
      "24 batch_normalization_2 False\n",
      "25 add_2 False\n",
      "26 block4_sepconv1_act True\n",
      "27 block4_sepconv1 True\n",
      "28 block4_sepconv1_bn True\n",
      "29 block4_sepconv2_act True\n",
      "30 block4_sepconv2 True\n",
      "31 block4_sepconv2_bn True\n",
      "32 conv2d_3 True\n",
      "33 block4_pool True\n",
      "34 batch_normalization_3 True\n",
      "35 add_3 True\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_4 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,618,185\n",
      "Non-trainable params: 245,344\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 85s 380ms/step - loss: 0.5595 - acc: 0.7131 - val_loss: 0.6848 - val_acc: 0.6562\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68476, saving model to Xception3 block4_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.4077 - acc: 0.8178 - val_loss: 0.6427 - val_acc: 0.6663\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68476 to 0.64266, saving model to Xception3 block4_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.3740 - acc: 0.8319 - val_loss: 0.9520 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.64266\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.3380 - acc: 0.8539 - val_loss: 0.8132 - val_acc: 0.6275\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.64266\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.3388 - acc: 0.8558 - val_loss: 0.7646 - val_acc: 0.6600\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.64266\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.2876 - acc: 0.8789 - val_loss: 0.7630 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.64266\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.2985 - acc: 0.8740 - val_loss: 1.0224 - val_acc: 0.5837\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.64266\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.2779 - acc: 0.8867 - val_loss: 1.0851 - val_acc: 0.6038\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.64266\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 82s 363ms/step - loss: 0.2755 - acc: 0.8860 - val_loss: 1.3579 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.64266\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 82s 364ms/step - loss: 0.2677 - acc: 0.8862 - val_loss: 1.3404 - val_acc: 0.5587\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.64266\n",
      "block3\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 False\n",
      "8 block2_sepconv1_bn False\n",
      "9 block2_sepconv2_act False\n",
      "10 block2_sepconv2 False\n",
      "11 block2_sepconv2_bn False\n",
      "12 conv2d_1 False\n",
      "13 block2_pool False\n",
      "14 batch_normalization_1 False\n",
      "15 add_1 False\n",
      "16 block3_sepconv1_act True\n",
      "17 block3_sepconv1 True\n",
      "18 block3_sepconv1_bn True\n",
      "19 block3_sepconv2_act True\n",
      "20 block3_sepconv2 True\n",
      "21 block3_sepconv2_bn True\n",
      "22 conv2d_2 True\n",
      "23 block3_pool True\n",
      "24 batch_normalization_2 True\n",
      "25 add_2 True\n",
      "26 block4_sepconv1_act True\n",
      "27 block4_sepconv1 True\n",
      "28 block4_sepconv1_bn True\n",
      "29 block4_sepconv2_act True\n",
      "30 block4_sepconv2 True\n",
      "31 block4_sepconv2_bn True\n",
      "32 conv2d_3 True\n",
      "33 block4_pool True\n",
      "34 batch_normalization_3 True\n",
      "35 add_3 True\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_4 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,754,249\n",
      "Non-trainable params: 109,280\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 92s 408ms/step - loss: 0.5701 - acc: 0.7021 - val_loss: 0.6333 - val_acc: 0.6713\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.63334, saving model to Xception3 block3_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.4157 - acc: 0.8139 - val_loss: 0.8125 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.63334\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.3636 - acc: 0.8438 - val_loss: 0.8607 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63334\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.3343 - acc: 0.8576 - val_loss: 1.1238 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.63334\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.3104 - acc: 0.8703 - val_loss: 0.8974 - val_acc: 0.6675\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.63334\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 88s 390ms/step - loss: 0.2934 - acc: 0.8789 - val_loss: 0.9067 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.63334\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.2910 - acc: 0.8774 - val_loss: 0.9650 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.63334\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 88s 390ms/step - loss: 0.2849 - acc: 0.8807 - val_loss: 0.7522 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.63334\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 88s 390ms/step - loss: 0.2680 - acc: 0.8900 - val_loss: 0.9132 - val_acc: 0.6713\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.63334\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 88s 391ms/step - loss: 0.2542 - acc: 0.8962 - val_loss: 0.8681 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.63334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block2\n",
      "0 input_2 False\n",
      "1 block1_conv1 False\n",
      "2 block1_conv1_bn False\n",
      "3 block1_conv1_act False\n",
      "4 block1_conv2 False\n",
      "5 block1_conv2_bn False\n",
      "6 block1_conv2_act False\n",
      "7 block2_sepconv1 True\n",
      "8 block2_sepconv1_bn True\n",
      "9 block2_sepconv2_act True\n",
      "10 block2_sepconv2 True\n",
      "11 block2_sepconv2_bn True\n",
      "12 conv2d_1 True\n",
      "13 block2_pool True\n",
      "14 batch_normalization_1 True\n",
      "15 add_1 True\n",
      "16 block3_sepconv1_act True\n",
      "17 block3_sepconv1 True\n",
      "18 block3_sepconv1_bn True\n",
      "19 block3_sepconv2_act True\n",
      "20 block3_sepconv2 True\n",
      "21 block3_sepconv2_bn True\n",
      "22 conv2d_2 True\n",
      "23 block3_pool True\n",
      "24 batch_normalization_2 True\n",
      "25 add_2 True\n",
      "26 block4_sepconv1_act True\n",
      "27 block4_sepconv1 True\n",
      "28 block4_sepconv1_bn True\n",
      "29 block4_sepconv2_act True\n",
      "30 block4_sepconv2 True\n",
      "31 block4_sepconv2_bn True\n",
      "32 conv2d_3 True\n",
      "33 block4_pool True\n",
      "34 batch_normalization_3 True\n",
      "35 add_3 True\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_4 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,789,513\n",
      "Non-trainable params: 74,016\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "225/225 [==============================] - 120s 531ms/step - loss: 0.5602 - acc: 0.7143 - val_loss: 0.5969 - val_acc: 0.7825\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59686, saving model to Xception3 block2_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.4004 - acc: 0.8158 - val_loss: 0.4645 - val_acc: 0.7875\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59686 to 0.46452, saving model to Xception3 block2_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.3570 - acc: 0.8404 - val_loss: 0.4609 - val_acc: 0.8050\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.46452 to 0.46092, saving model to Xception3 block2_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.3240 - acc: 0.8582 - val_loss: 0.4449 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46092 to 0.44493, saving model to Xception3 block2_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.3274 - acc: 0.8600 - val_loss: 0.4092 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44493 to 0.40916, saving model to Xception3 block2_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.2974 - acc: 0.8756 - val_loss: 0.4824 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40916\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2893 - acc: 0.8814 - val_loss: 0.5325 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.40916\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2797 - acc: 0.8849 - val_loss: 0.4864 - val_acc: 0.7913\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40916\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2677 - acc: 0.8881 - val_loss: 0.4842 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40916\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2621 - acc: 0.8919 - val_loss: 0.5129 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40916\n",
      "block1\n",
      "0 input_2 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv1_bn True\n",
      "3 block1_conv1_act True\n",
      "4 block1_conv2 True\n",
      "5 block1_conv2_bn True\n",
      "6 block1_conv2_act True\n",
      "7 block2_sepconv1 True\n",
      "8 block2_sepconv1_bn True\n",
      "9 block2_sepconv2_act True\n",
      "10 block2_sepconv2 True\n",
      "11 block2_sepconv2_bn True\n",
      "12 conv2d_1 True\n",
      "13 block2_pool True\n",
      "14 batch_normalization_1 True\n",
      "15 add_1 True\n",
      "16 block3_sepconv1_act True\n",
      "17 block3_sepconv1 True\n",
      "18 block3_sepconv1_bn True\n",
      "19 block3_sepconv2_act True\n",
      "20 block3_sepconv2 True\n",
      "21 block3_sepconv2_bn True\n",
      "22 conv2d_2 True\n",
      "23 block3_pool True\n",
      "24 batch_normalization_2 True\n",
      "25 add_2 True\n",
      "26 block4_sepconv1_act True\n",
      "27 block4_sepconv1 True\n",
      "28 block4_sepconv1_bn True\n",
      "29 block4_sepconv2_act True\n",
      "30 block4_sepconv2 True\n",
      "31 block4_sepconv2_bn True\n",
      "32 conv2d_3 True\n",
      "33 block4_pool True\n",
      "34 batch_normalization_3 True\n",
      "35 add_3 True\n",
      "36 block5_sepconv1_act True\n",
      "37 block5_sepconv1 True\n",
      "38 block5_sepconv1_bn True\n",
      "39 block5_sepconv2_act True\n",
      "40 block5_sepconv2 True\n",
      "41 block5_sepconv2_bn True\n",
      "42 block5_sepconv3_act True\n",
      "43 block5_sepconv3 True\n",
      "44 block5_sepconv3_bn True\n",
      "45 add_4 True\n",
      "46 block6_sepconv1_act True\n",
      "47 block6_sepconv1 True\n",
      "48 block6_sepconv1_bn True\n",
      "49 block6_sepconv2_act True\n",
      "50 block6_sepconv2 True\n",
      "51 block6_sepconv2_bn True\n",
      "52 block6_sepconv3_act True\n",
      "53 block6_sepconv3 True\n",
      "54 block6_sepconv3_bn True\n",
      "55 add_5 True\n",
      "56 block7_sepconv1_act True\n",
      "57 block7_sepconv1 True\n",
      "58 block7_sepconv1_bn True\n",
      "59 block7_sepconv2_act True\n",
      "60 block7_sepconv2 True\n",
      "61 block7_sepconv2_bn True\n",
      "62 block7_sepconv3_act True\n",
      "63 block7_sepconv3 True\n",
      "64 block7_sepconv3_bn True\n",
      "65 add_6 True\n",
      "66 block8_sepconv1_act True\n",
      "67 block8_sepconv1 True\n",
      "68 block8_sepconv1_bn True\n",
      "69 block8_sepconv2_act True\n",
      "70 block8_sepconv2 True\n",
      "71 block8_sepconv2_bn True\n",
      "72 block8_sepconv3_act True\n",
      "73 block8_sepconv3 True\n",
      "74 block8_sepconv3_bn True\n",
      "75 add_7 True\n",
      "76 block9_sepconv1_act True\n",
      "77 block9_sepconv1 True\n",
      "78 block9_sepconv1_bn True\n",
      "79 block9_sepconv2_act True\n",
      "80 block9_sepconv2 True\n",
      "81 block9_sepconv2_bn True\n",
      "82 block9_sepconv3_act True\n",
      "83 block9_sepconv3 True\n",
      "84 block9_sepconv3_bn True\n",
      "85 add_8 True\n",
      "86 block10_sepconv1_act True\n",
      "87 block10_sepconv1 True\n",
      "88 block10_sepconv1_bn True\n",
      "89 block10_sepconv2_act True\n",
      "90 block10_sepconv2 True\n",
      "91 block10_sepconv2_bn True\n",
      "92 block10_sepconv3_act True\n",
      "93 block10_sepconv3 True\n",
      "94 block10_sepconv3_bn True\n",
      "95 add_9 True\n",
      "96 block11_sepconv1_act True\n",
      "97 block11_sepconv1 True\n",
      "98 block11_sepconv1_bn True\n",
      "99 block11_sepconv2_act True\n",
      "100 block11_sepconv2 True\n",
      "101 block11_sepconv2_bn True\n",
      "102 block11_sepconv3_act True\n",
      "103 block11_sepconv3 True\n",
      "104 block11_sepconv3_bn True\n",
      "105 add_10 True\n",
      "106 block12_sepconv1_act True\n",
      "107 block12_sepconv1 True\n",
      "108 block12_sepconv1_bn True\n",
      "109 block12_sepconv2_act True\n",
      "110 block12_sepconv2 True\n",
      "111 block12_sepconv2_bn True\n",
      "112 block12_sepconv3_act True\n",
      "113 block12_sepconv3 True\n",
      "114 block12_sepconv3_bn True\n",
      "115 add_11 True\n",
      "116 block13_sepconv1_act True\n",
      "117 block13_sepconv1 True\n",
      "118 block13_sepconv1_bn True\n",
      "119 block13_sepconv2_act True\n",
      "120 block13_sepconv2 True\n",
      "121 block13_sepconv2_bn True\n",
      "122 conv2d_4 True\n",
      "123 block13_pool True\n",
      "124 batch_normalization_4 True\n",
      "125 add_12 True\n",
      "126 block14_sepconv1 True\n",
      "127 block14_sepconv1_bn True\n",
      "128 block14_sepconv1_act True\n",
      "129 block14_sepconv2 True\n",
      "130 block14_sepconv2_bn True\n",
      "131 block14_sepconv2_act True\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             (None, 3, 3, 2048)        20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 121s 536ms/step - loss: 0.5412 - acc: 0.7301 - val_loss: 0.4176 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.41764, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.3946 - acc: 0.8219 - val_loss: 0.3622 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.41764 to 0.36225, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.3565 - acc: 0.8486 - val_loss: 0.3186 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.36225 to 0.31861, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 115s 511ms/step - loss: 0.3325 - acc: 0.8574 - val_loss: 0.2802 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31861 to 0.28023, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.3100 - acc: 0.8689 - val_loss: 0.2536 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.28023 to 0.25365, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2924 - acc: 0.8753 - val_loss: 0.2948 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25365\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.2675 - acc: 0.8892 - val_loss: 0.1968 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.25365 to 0.19679, saving model to Xception3 block1_weights.hdf5\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 115s 512ms/step - loss: 0.2686 - acc: 0.8874 - val_loss: 0.2364 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19679\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2742 - acc: 0.8921 - val_loss: 0.2225 - val_acc: 0.9213\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19679\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 115s 513ms/step - loss: 0.2397 - acc: 0.9032 - val_loss: 0.2322 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19679\n"
     ]
    }
   ],
   "source": [
    "for j in range(14,0,-1): #verander hier het aantal blokken dat je pretrained model heeft\n",
    "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    input = Input(input_shape)\n",
    "    pretrained = Xception(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "    for layer in pretrained.layers:\n",
    "            layer.trainable = False            \n",
    "\n",
    "    string = 'block'+str(j)\n",
    "    indices = [i for i, s in enumerate(layernames) if string in s]      \n",
    "    for layer in pretrained.layers[min(indices):]:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    output = pretrained(input)\n",
    "    output = GlobalAveragePooling2D()(output)\n",
    "    output = Dropout(0.5)(output)\n",
    "    output = Dense(1, activation='sigmoid')(output)\n",
    "\n",
    "    # Check the trainable status of the individual layers\n",
    "    #for layer in pretrained.layers:\n",
    "    #    print(layer, layer.trainable)\n",
    "\n",
    "    model = Model(input, output)\n",
    "    model.compile(SGD(lr=0.001, momentum=0.95), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "    #\n",
    "    # print a summary of the model on screen\n",
    "    print(string)\n",
    "    for i,layer in enumerate(pretrained.layers):\n",
    "        print(i,layer.name,layer.trainable)\n",
    "    model.summary()\n",
    "        \n",
    "    # save the model and weights\n",
    "    model_name = 'Xception3 '+string\n",
    "    model_filepath = model_name + '.json'\n",
    "    weights_filepath = model_name + '_weights.hdf5'\n",
    "\n",
    "    model_json = model.to_json() # serialize model to JSON\n",
    "    with open(model_filepath, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "\n",
    "    # define the model checkpoint and Tensorboard callbacks\n",
    "    checkpoint = ModelCheckpoint(weights_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    tensorboard = TensorBoard(os.path.join('logs', model_name))\n",
    "    callbacks_list = [checkpoint, tensorboard]\n",
    "\n",
    "\n",
    "    # train the model, note that we define \"mini-epochs\"\n",
    "    train_steps = train_gen.n//train_gen.batch_size//20\n",
    "    val_steps = val_gen.n//val_gen.batch_size//20\n",
    "\n",
    "    # since the model is trained for only 10 \"mini-epochs\", i.e. half of the data is\n",
    "    # not used during training\n",
    "\n",
    "    history = model.fit_generator(train_gen, steps_per_epoch=train_steps,\n",
    "                        validation_data=val_gen,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=10,\n",
    "                        callbacks=callbacks_list)\n",
    "    K.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
